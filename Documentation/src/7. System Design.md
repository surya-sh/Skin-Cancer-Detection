---
updated: 2025-04-13T14:10
---

System Design
=============

Overview of Architecture
------------------------

The proposed architecture consists of four deep learning models—EfficientNetV2S, EfficientNetV2M, InceptionResNetV2, and XceptionNet—each trained independently on the HAM10000 dataset. These models are then combined through an ensemble averaging mechanism. The ensemble model takes the dermatoscopic image as input, preprocesses it to match the input dimensions of the models, and feeds it into each network. The resulting predictions are averaged to generate a final output. This ensemble-based approach reduces individual model biases and improves classification robustness. The final model is then integrated into a Gradio web application for real-time use.

Functional Architecture
-----------------------

The system begins with image acquisition through the web interface. The image is preprocessed—resized, normalized, and augmented as needed—before being passed to the ensemble model. Each of the four CNN models processes the image independently, and their outputs are combined. The combined prediction is then decoded into one of the seven skin cancer classes. Finally, the result, including a detailed description of the condition, is displayed to the user. This flow ensures end-to-end automation, from user input to diagnosis delivery.

Transformer Architecture (Reference)
------------------------------------

While not directly used in this project, the Transformer architecture is briefly explored for its potential future use in skin lesion classification. Originally developed for NLP, Transformers have shown success in vision tasks through Vision Transformers (ViT). These models use self-attention mechanisms to understand global image features, making them valuable for detecting skin lesions that vary greatly in appearance. In future enhancements, this architecture may replace or augment CNN-based approaches.

UML Diagrams
------------

### Use Case Diagram ###

This diagram showcases the interaction between the user (dermatologist or patient) and the system. The main use case involves uploading an image and receiving a diagnosis. Other use cases include model training, result viewing, and feedback submission.

```plantuml
@startuml
title Skin Cancer Detection System - Use Case Diagram

actor Dermatologist
actor Patient

rectangle "Skin Cancer Detection System" {
  usecase "Upload Image" as UC1
  usecase "Receive Diagnosis" as UC2
  usecase "View Results" as UC3
  usecase "Submit Feedback" as UC4
  usecase "Model Training" as UC5
}

Dermatologist --> UC1
Dermatologist --> UC2
Dermatologist --> UC3
Dermatologist --> UC4
Dermatologist --> UC5

Patient --> UC1
Patient --> UC2
Patient --> UC3
Patient --> UC4

UC1 --> UC2  : triggers

@enduml

```


### Sequence Diagram ###

This diagram represents the chronological flow: the user uploads an image, the image is processed, predictions are generated by the ensemble model, and the result is returned. It captures the real-time, interactive nature of the system.

```mermaid
sequenceDiagram
    participant Patient
    participant Doctor
    participant ClientApp as Client Application
    participant Server
    participant DB as Database

    %% Patient uploads image for diagnosis
    Patient->>ClientApp: Upload skin image
    ClientApp->>Server: Send image data
    Server->>Server: Preprocess image
    Server->>Server: Run CNN model
    Server->>DB: Store diagnosis result
    DB-->>Server: Confirm storage
    Server->>ClientApp: Return diagnosis result
    ClientApp->>Patient: Display diagnosis

    %% Doctor logs in to view patient report
    Doctor->>ClientApp: Login and request patient reports
    ClientApp->>Server: Request reports for patient
    Server->>DB: Query diagnosis data
    DB-->>Server: Return diagnosis data
    Server->>ClientApp: Send report to doctor
    ClientApp->>Doctor: Display report
```
### Activity Diagram ###

The activity diagram outlines the complete workflow—from system initialization, image upload, and preprocessing, to prediction generation and display. It provides a visual representation of the logic and sequence of operations, ensuring a clear understanding of system functionality.

```plantuml
@startuml
start

:User starts session;
if (User Type?) then (Dermatologist)
  :Display advanced options;
elseif (Patient)
  :Display standard options;
endif

partition "Diagnosis Process" {
  :Upload skin lesion image;
  :Preprocess image data;
  :Run CNN model for diagnosis;
  if ("Diagnosis Result Positive?") then (yes)
    :Indicate "Potential Malignancy";
  else (no)
    :Indicate "Likely Benign";
  endif
  :Store diagnosis result;
  :Display result to user;
}

partition "Additional Operations" {
  :Option to view detailed results;
  if ("View Detailed Results?") then (yes)
    :Show extended diagnosis report;
  else (no)
    :Return to main menu;
  endif

  :Option to submit feedback;
  if ("Feedback Submitted?") then (yes)
    :Receive and log feedback;
  endif
}

partition "Model Management" {
  :Initiate model training (Admin/Advanced);
  :Monitor training progress;
  :Update CNN model with new data;
}

stop
@enduml
```

## Deployment Diagram
This deployment diagram illustrates the architecture for a skin cancer detection system built on a convolutional neural network (CNN) model. In the diagram, a client device (which can be a web or mobile application) sends HTTP/HTTPS requests to a web server hosting a REST API, which forwards image data for analysis to an inference server where the CNN model is deployed. The inference server processes the incoming images, performs diagnosis using the trained model, and then interacts with a centralized database that stores both raw image data and the diagnostic results. This high-level overview not only outlines the data flow—from image capture to storage of results—but also identifies key considerations for production environments, such as the potential incorporation of load balancers, security measures, and additional nodes to support model training and GPU acceleration.
```plantuml
@startuml
skinparam node {
    BackgroundColor LightBlue
    BorderColor Black
}

'-------------------------
' Client Node
'-------------------------
node "Client Device" {
    component "UI Application\n(Web/Mobile)" as UI
}

'-------------------------
' Web Server Node
'-------------------------
node "Web Server" {
    component "REST API Service" as API
}

'-------------------------
' Application / Inference Server Node
'-------------------------
node "Inference Server" {
    component "CNN Model Service\n(Skin Cancer Detection)" as CNN
}

'-------------------------
' Database Node
'-------------------------
database "Image & Data Database" as DB

'-------------------------
' Communication Paths
'-------------------------
UI --> API : HTTP/HTTPS Request (Upload Image)
API --> CNN : API Call (Trigger Inference)
CNN --> DB : Read/Write (Patient Data & Results)
@enduml

```


# Overall Architecture
```mermaid
architecture-beta
    group api(cloud)[Web Service]

    service db(database)[Database] in api
    service client(internet)[Client] in api
    service server(server)[Server] in api

    db:L -- R:server
    client:T -- B:server
```
```mermaid
%% Corrected Overall Architecture Diagram for Skin Cancer Detection System
architecture-beta
  group client_device(cloud)[Client Device]
    service ui_app(internet)[Gradio Web App] in client_device
  group web_server(server)[Web Server]
    service rest_api(server)[REST API Service] in web_server
  group inference_server(server)[Inference Server]
    service ensemble_cnn(server)[Ensemble CNN Service] in inference_server
  group database(database)[Data Storage]
    service data_db(database)[Image and Diagnosis Database] in database
  group training_module(server)[Training Module]
    service model_training(server)[Model Training Service] in training_module
  group future_module(server)[Future Enhancements]
    service transformer_module(server)[Transformer Module Experimental] in future_module

  ui_app:R <--> L:rest_api
  rest_api:R -- L:ensemble_cnn
  ensemble_cnn:B -- T:data_db
  rest_api:R -- L:data_db
  rest_api:R -- L:model_training
  ensemble_cnn:R -- L:transformer_module

```

```mermaid
%% Corrected Overall Architecture Diagram for Skin Cancer Detection System
architecture-beta
 group model(server)[Model Management]
    service ui_app(internet)[Gradio Web App]
    service rest_api(server)[REST API Service]
    service ensemble_cnn(server)[Ensemble CNN Service] in model
  group database(database)[Data Storage]
    service data_db(database)[Image and Diagnosis Database] in database
    service model_training(server)[Model Training Service] in model
    service transformer_module(server)[Transformer Module Experimental] in model

  ui_app:R <--> L:rest_api
  rest_api:R -- L:ensemble_cnn
  ensemble_cnn:B -- T:data_db
  rest_api:R -- L:data_db
  rest_api:R -- L:model_training
  ensemble_cnn:R -- L:transformer_module

```


```plantuml
@startuml
!define lightColor #ffffff
!define darkColor  #222222
' Assume gv(switch) is true for light mode, false for dark mode.
skinparam backgroundColor $if(gv(switch), lightColor, darkColor)
Alice -> Bob : Hello in dynamic mode!
@enduml

```
